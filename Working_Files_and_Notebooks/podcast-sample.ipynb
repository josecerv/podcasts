{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to SQLite database.\n",
      "Total podcasts in the sample before filtering: 122583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcerv\\AppData\\Local\\Temp\\ipykernel_27928\\4069753874.py:162: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  genres = podcast_genres_df.groupby('podcast_id').apply(get_genres).reset_index()\n",
      "C:\\Users\\jcerv\\AppData\\Local\\Temp\\ipykernel_27928\\4069753874.py:202: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  podcasts_df = podcasts_df.groupby('email', group_keys=False).apply(choose_podcast)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total podcasts in the sample after filtering duplicates by email: 106517\n",
      "Sample saved to podcasts_sample.csv\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np  # Import numpy for numeric operations and NaN handling\n",
    "\n",
    "# Paths and connection strings\n",
    "sqlite_db_path = r\"C:\\Users\\jcerv\\Jose\\podcasts\\podcasts (read-only).db\"\n",
    "\n",
    "# Output file path (CSV)\n",
    "output_file = 'podcasts_sample.csv'\n",
    "\n",
    "# Connect to the SQLite database\n",
    "try:\n",
    "    sqlite_conn = sqlite3.connect(sqlite_db_path)\n",
    "    print(\"Connected to SQLite database.\")\n",
    "except sqlite3.Error as e:\n",
    "    print(f\"An error occurred while connecting to SQLite: {e}\")\n",
    "    exit(1)\n",
    "    \n",
    "# Define the common filters\n",
    "common_filters = \"\"\"\n",
    "    p.country = 'United States'\n",
    "    AND p.email IS NOT NULL \n",
    "    AND p.email != ''\n",
    "    AND p.language = 'English'\n",
    "    AND p.rss IS NOT NULL\n",
    "    AND p.has_guest_interviews = 1\n",
    "    AND p.episode_count > 7\n",
    "    AND strftime('%Y', p.latest_episode_pub_date) IN ('2024', '2025')\n",
    "    AND (\n",
    "        (p.itunes_id IS NOT NULL AND p.itunes_id != '')\n",
    "        OR (p.spotify IS NOT NULL AND p.spotify != '')\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "# Query to get podcast data without genres\n",
    "podcast_query = f\"\"\"\n",
    "SELECT\n",
    "    p.podcast_id,\n",
    "    p.title,\n",
    "    p.artwork_image,\n",
    "    p.artwork_thumbnail,\n",
    "    p.listen_score,\n",
    "    p.listen_score_global_rank,\n",
    "    p.rss,\n",
    "    p.publisher,\n",
    "    p.description,\n",
    "    p.language,\n",
    "    p.country,\n",
    "    p.email,\n",
    "    p.website,\n",
    "    p.episode_count,\n",
    "    p.audio_length_seconds,\n",
    "    p.update_frequency_hours,\n",
    "    p.latest_episode_pub_date,\n",
    "    p.earliest_episode_pub_date,\n",
    "    p.has_guest_interviews,\n",
    "    p.has_sponsors,\n",
    "    p.itunes_id,\n",
    "    p.twitter,\n",
    "    p.instagram,\n",
    "    p.patreon,\n",
    "    p.wechat,\n",
    "    p.facebook,\n",
    "    p.amazon_music,\n",
    "    p.spotify,\n",
    "    p.youtube,\n",
    "    p.linkedin,\n",
    "    p.wikipedia,\n",
    "    p.url1,\n",
    "    p.url2,\n",
    "    p.url3,\n",
    "    p.explicit,\n",
    "    p.is_complete,\n",
    "    p.type,\n",
    "    p.imported_time\n",
    "FROM podcasts p\n",
    "WHERE {common_filters}\n",
    "\"\"\"\n",
    "\n",
    "# Query to get podcast_genres mapping\n",
    "podcast_genres_query = \"\"\"\n",
    "SELECT\n",
    "    pg.podcast_id,\n",
    "    pg.genre_id\n",
    "FROM podcast_genres pg\n",
    "\"\"\"\n",
    "\n",
    "# Query to get genre hierarchy\n",
    "genres_query = \"\"\"\n",
    "SELECT\n",
    "    g.id,\n",
    "    g.name,\n",
    "    g.parent_id\n",
    "FROM genres g\n",
    "\"\"\"\n",
    "\n",
    "# Read podcast data into DataFrame\n",
    "podcasts_df = pd.read_sql_query(podcast_query, sqlite_conn)\n",
    "\n",
    "# Read podcast_genres mapping into DataFrame\n",
    "podcast_genres_df = pd.read_sql_query(podcast_genres_query, sqlite_conn)\n",
    "\n",
    "# Read genres into DataFrame\n",
    "genres_df = pd.read_sql_query(genres_query, sqlite_conn)\n",
    "\n",
    "# Close the connection\n",
    "sqlite_conn.close()\n",
    "\n",
    "# Print number of podcasts retrieved\n",
    "total_podcasts = len(podcasts_df)\n",
    "print(f\"Total podcasts in the sample before filtering: {total_podcasts}\")\n",
    "\n",
    "# Build a genre hierarchy to map each genre to its primary genre\n",
    "# First, set the index of genres_df to id for easy lookup\n",
    "genres_df.set_index('id', inplace=True)\n",
    "\n",
    "# Ensure that 'parent_id' is numeric and handle missing values\n",
    "genres_df['parent_id'] = genres_df['parent_id'].astype(pd.Int64Dtype())\n",
    "\n",
    "# Function to find the primary genre for a given genre_id\n",
    "def find_primary_genre(genre_id):\n",
    "    current_id = genre_id\n",
    "    while current_id is not None and not pd.isna(current_id):\n",
    "        try:\n",
    "            parent_id = genres_df.at[current_id, 'parent_id']\n",
    "        except KeyError:\n",
    "            # If the genre_id is not found in genres_df, return None\n",
    "            return None\n",
    "\n",
    "        if pd.isna(parent_id) or parent_id is None:\n",
    "            # Reached the top without finding parent_id = 67\n",
    "            return None\n",
    "        elif parent_id == 67:\n",
    "            # If parent_id is 67, current genre is primary\n",
    "            return genres_df.at[current_id, 'name']\n",
    "        else:\n",
    "            # Move up the hierarchy\n",
    "            current_id = parent_id  # parent_id should be an integer or NA\n",
    "    return None\n",
    "\n",
    "# Add the genre names to podcast_genres_df\n",
    "podcast_genres_df['genre_name'] = podcast_genres_df['genre_id'].map(genres_df['name'])\n",
    "\n",
    "# Find the primary genre for each genre_id\n",
    "podcast_genres_df['primary_genre'] = podcast_genres_df['genre_id'].apply(find_primary_genre)\n",
    "\n",
    "# Remove rows where 'primary_genre' is None (could not find a primary genre)\n",
    "podcast_genres_df = podcast_genres_df[podcast_genres_df['primary_genre'].notna()]\n",
    "\n",
    "# Now, for each podcast, exclude primary_genres from secondary_genres\n",
    "def get_genres(group):\n",
    "    primary_genres_set = set(group['primary_genre'].dropna())\n",
    "    genre_names_set = set(group['genre_name'].dropna())\n",
    "    # Exclude primary genres from secondary genres\n",
    "    secondary_genres_set = genre_names_set - primary_genres_set\n",
    "    primary_genres_str = ', '.join(sorted(primary_genres_set))\n",
    "    secondary_genres_str = ', '.join(sorted(secondary_genres_set))\n",
    "    return pd.Series({'primary_genre': primary_genres_str, 'secondary_genres': secondary_genres_str})\n",
    "\n",
    "# Apply the function to each group to combine genres for each podcast.\n",
    "genres = podcast_genres_df.groupby('podcast_id').apply(get_genres).reset_index()\n",
    "\n",
    "# Merge genres back to podcasts_df\n",
    "podcasts_df = podcasts_df.merge(genres, on='podcast_id', how='inner')\n",
    "\n",
    "# Function to choose a single podcast per email\n",
    "def choose_podcast(group):\n",
    "    # If there's only one podcast for this email, just return it.\n",
    "    if len(group) == 1:\n",
    "        return group\n",
    "\n",
    "    # Separate out rows with a valid (non-null) listen_score.\n",
    "    valid_scores = group[group['listen_score'].notna()]\n",
    "\n",
    "    # If no rows have a valid listen_score, randomly select one from the entire group.\n",
    "    if valid_scores.empty:\n",
    "        return group.sample(n=1)\n",
    "    \n",
    "    # Otherwise, sort only the rows with valid listen_score.\n",
    "    sorted_group = valid_scores.sort_values(by='listen_score')\n",
    "\n",
    "    # Find the median position (if even, picks the lower median).\n",
    "    median_index = len(sorted_group) // 2\n",
    "    median_score = sorted_group.iloc[median_index]['listen_score']\n",
    "\n",
    "    # Use np.isclose for a tolerant comparison of the listen_score.\n",
    "    median_group = sorted_group[np.isclose(sorted_group['listen_score'], median_score)]\n",
    "    \n",
    "    # Fallback: if median_group is empty (which is unlikely), fallback to the row at median_index.\n",
    "    if median_group.empty:\n",
    "        median_group = sorted_group.iloc[[median_index]]\n",
    "    \n",
    "    # If the selection is ambiguous (i.e., more than one podcast has the median score or the original group has exactly 2),\n",
    "    # randomly select one of the candidates.\n",
    "    if len(median_group) > 1 or len(group) == 2:\n",
    "        return median_group.sample(n=1)\n",
    "    else:\n",
    "        return median_group\n",
    "\n",
    "# Group by email and apply the selection function to remove duplicate podcasts.\n",
    "podcasts_df = podcasts_df.groupby('email', group_keys=False).apply(choose_podcast)\n",
    "\n",
    "# Print number of podcasts after filtering duplicates by email.\n",
    "final_podcast_count = len(podcasts_df)\n",
    "print(f\"Total podcasts in the sample after filtering duplicates by email: {final_podcast_count}\")\n",
    "\n",
    "# Save to CSV\n",
    "podcasts_df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "print(f\"Sample saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcerv\\AppData\\Local\\Temp\\ipykernel_82340\\4067597913.py:5: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  podcasts_df = pd.read_csv('podcasts_sample.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of podcasts in filtered sample: 66042\n",
      "Number of podcasts with Society & Culture, Business, or News genres: 32256\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Read the CSV file\n",
    "podcasts_df = pd.read_csv('podcasts_sample.csv')\n",
    "\n",
    "# Read the JSONL file with UTF-8 encoding and extract podcast_ids\n",
    "prod_db_ids = set()\n",
    "with open('prod_db.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        prod_db_ids.add(data['podcast_id'])\n",
    "\n",
    "# Filter the CSV to include only podcasts in prod_db.jsonl\n",
    "filtered_df = podcasts_df[podcasts_df['podcast_id'].isin(prod_db_ids)]\n",
    "\n",
    "# Count genres of interest\n",
    "genre_count = 0\n",
    "for genres in filtered_df['primary_genre']:\n",
    "    genre_list = [g.strip() for g in str(genres).split(',')]\n",
    "    if any(genre in ['Society & Culture', 'Business', 'News'] for genre in genre_list):\n",
    "        genre_count += 1\n",
    "\n",
    "print(f\"Number of podcasts in filtered sample: {len(filtered_df)}\")\n",
    "print(f\"Number of podcasts with Society & Culture, Business, or News genres: {genre_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv('podcasts_final_sample.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
